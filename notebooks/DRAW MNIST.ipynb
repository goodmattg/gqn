{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_ATTN = True\n",
    "WRITE_ATTN = True\n",
    "\n",
    "A, B = 28, 28  # image width,height\n",
    "img_size = B * A  # the canvas size\n",
    "enc_size = 256  # number of hidden units / output size in LSTM\n",
    "dec_size = 256\n",
    "\n",
    "# Glimpse grid dimensions ASSUMED TO BE ODD\n",
    "read_n = 5  # read glimpse grid width/height\n",
    "write_n = 5  # write glimpse grid width/height\n",
    "read_size = 2 * read_n * read_n if READ_ATTN else 2 * img_size\n",
    "write_size = write_n * write_n if WRITE_ATTN else img_size\n",
    "\n",
    "z_size = 10  # QSampler output size\n",
    "SEQ_LENGTH = 10  # MNIST generation sequence length\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_iters = 10000\n",
    "learning_rate = 1e-3  # learning rate for optimizer\n",
    "eps = 1e-8  # epsilon for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/mnist\"\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: (3, 28, 28)\n",
      "Letter: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x131063c50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = train_ds.__iter__().next()\n",
    "sample = x[0]\n",
    "label = y[0]\n",
    "print(\"Batch Shape: {}\".format(x.shape))\n",
    "print(\"Letter: {}\".format(label))\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterbank(gx, gy, sigma2, delta, N):\n",
    "    # Grid is 0-indexed, but formula is 1-indexed...\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(1, N+1), tf.float32), [1, -1])\n",
    "    mu_x = gx + (grid_i - N / 2 - 0.5) * delta  # eq 19\n",
    "    mu_y = gy + (grid_i - N / 2 - 0.5) * delta  # eq 20\n",
    "    a_range = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n",
    "    b_range = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n",
    "    mu_x = tf.reshape(mu_x, [-1, N, 1])\n",
    "    mu_y = tf.reshape(mu_y, [-1, N, 1])\n",
    "    sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "    Fx = tf.exp(-tf.square(a_range - mu_x) / (2 * sigma2))\n",
    "    Fy = tf.exp(-tf.square(b_range - mu_y) / (2 * sigma2))  # batch x N x B\n",
    "    # normalize, sum over A and B dims\n",
    "    Fx = Fx / tf.maximum(tf.reduce_sum(Fx, [1,2]), eps)\n",
    "    Fy = Fy / tf.maximum(tf.reduce_sum(Fy, [1,2]), eps)\n",
    "    return Fx, Fy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sample check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch sample check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-635f3e7d37f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilterbank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mFx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mFy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gx' is not defined"
     ]
    }
   ],
   "source": [
    "Fx, Fy = filterbank(gx, gy, sigma2, delta, N)\n",
    "Fx = tf.tile(Fx, [BATCH_SIZE, 1, 1])\n",
    "Fy = tf.tile(Fy, [BATCH_SIZE, 1, 1])\n",
    "sample_batch = tf.cast(x, tf.float32)\n",
    "\n",
    "Fxt = tf.transpose(Fx, perm=[0, 2, 1])\n",
    "\n",
    "glimpses = tf.linalg.matmul(Fy, tf.linalg.matmul(sample_batch, Fxt))\n",
    "glimpses = tf.reshape(glimpses, [-1, N * N])\n",
    "# print(Fxt.shape)\n",
    "# print(Fy.shape)\n",
    "# print(sample_batch.shape)\n",
    "# print(Fx.shape)\n",
    "print(glimpses.shape)\n",
    "\n",
    "# for i in range(BATCH_SIZE):\n",
    "#     plt.imshow(x[i])\n",
    "#     plt.figure()\n",
    "#     plt.imshow(glimpses[i])\n",
    "#     plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filterbank(gx, gy, sigma2, delta, N):\n",
    "    # Grid is 0-indexed, but formula is 1-indexed...\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(1, N+1), tf.float32), [1, -1])\n",
    "    mu_x = gx + (grid_i - N / 2 - 0.5) * delta  # eq 19\n",
    "    mu_y = gy + (grid_i - N / 2 - 0.5) * delta  # eq 20\n",
    "    a_range = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n",
    "    b_range = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n",
    "    mu_x = tf.reshape(mu_x, [-1, N, 1])\n",
    "    mu_y = tf.reshape(mu_y, [-1, N, 1])\n",
    "    sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "    Fx = tf.exp(-tf.square(a_range - mu_x) / (2 * sigma2))\n",
    "    Fy = tf.exp(-tf.square(b_range - mu_y) / (2 * sigma2))  # batch x N x B\n",
    "    # normalize, sum over A and B dims\n",
    "    Fx = Fx / tf.maximum(tf.reduce_sum(Fx, [1,2]), eps)\n",
    "    Fy = Fy / tf.maximum(tf.reduce_sum(Fy, [1,2]), eps)\n",
    "    return Fx, Fy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRAWRNNCell(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 state_dim,\n",
    "                 read_attention=True,\n",
    "                 write_attention=True,\n",
    "                 read_n=5,\n",
    "                 write_n=5,\n",
    "                **kwargs):\n",
    "        \n",
    "        # Encoder/Decoder LSTM Cells track their own kernels\n",
    "        self.lstm_encoder = tf.keras.layers.LSTMCell(enc_size, kernel_initializer=\"zeros\")\n",
    "        self.lstm_decoder = tf.keras.layers.LSTMCell(dec_size, kernel_initializer=\"zeros\")\n",
    "        \n",
    "        self.use_read_attention = read_attention\n",
    "        self.use_write_attention = write_attention\n",
    "        \n",
    "        self.output_size = output_dim\n",
    "        self.state_size = state_dim\n",
    "        \n",
    "        self.read_n = read_n\n",
    "        self.write_n = write_n\n",
    "        \n",
    "        super(DRAWRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.attention_kernel = self.add_weight(\n",
    "            shape=(dec_size, self.read_n),\n",
    "            initializer='glorot_uniform',\n",
    "            name='W')\n",
    "        \n",
    "        self.attention_bias = self.add_weight(\n",
    "            shape=(self.read_n),\n",
    "            initializer='zeros',\n",
    "            name='b')\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def encode(self, input, state):\n",
    "        return self.lstm_encoder(input, state)\n",
    "    \n",
    "    def decode(self, input, state):\n",
    "        return self.lstm_decoder(input, state)\n",
    "        \n",
    "    def call(self, inputs, states):        \n",
    "        c_prev, enc_prev, dec_prev = states\n",
    "        x = inputs\n",
    "        # Error image (3)\n",
    "        x_hat = x - tf.sigmoid(c_prev)\n",
    "        # Read (4)\n",
    "        r = self.read(x, x_hat, dec_prev)\n",
    "        # Encode (5)\n",
    "        h_enc, enc_state = self.encode(tf.concat([r, dec_prev], 1), enc_prev)\n",
    "        # Sample (6)\n",
    "        z = sampleQ(h_enc)\n",
    "#         z, mus[t], logsigmas[t], sigmas[t] = sampleQ(h_enc)\n",
    "        # Decode (7)\n",
    "        h_dec, dec_state = self.decode(z, dec_prev)\n",
    "        # Write (8)\n",
    "        c_out = c_prev + write(h_dec)\n",
    "    \n",
    "        # Return canvas as output & pass along as part of state\n",
    "        return c_out, [c_out, h_enc, h_dec]\n",
    "    \n",
    "    def attn_window(self, h_dec, N):\n",
    "        import pdb; pdb.set_trace()\n",
    "        attention_params = tf.matmul(h_dec, self.attention_kernel) + self.attention_bias\n",
    "        \n",
    "        def filter_batch(batch, Fx, Fy, gamma, N):\n",
    "            Fx = tf.tile(Fx, [BATCH_SIZE, 1, 1])\n",
    "            Fy = tf.tile(Fy, [BATCH_SIZE, 1, 1])\n",
    "            Fxt = tf.transpose(Fx, perm=[0, 2, 1])\n",
    "            glimpses = tf.linalg.matmul(Fy, tf.linalg.matmul(sample_batch, Fxt))\n",
    "            glimpses = tf.reshape(glimpse, [-1, N * N])\n",
    "            return glimpses * gamma\n",
    "        \n",
    "        gx_, gy_, log_sigma2, log_delta, log_gamma = tf.split(attention_params, 5, 1)\n",
    "        gx = (A + 1) / 2 * (gx_ + 1)\n",
    "        gy = (B + 1) / 2 * (gy_ + 1)\n",
    "        sigma2 = tf.exp(log_sigma2)\n",
    "        delta = (max(A, B) - 1) / (N - 1) * tf.exp(log_delta)  # batch x N\n",
    "        return gaussian_filterbank(gx, gy, sigma2, delta, N) + (tf.exp(log_gamma),)\n",
    "    \n",
    "    def read(self, x, x_hat, h_dec_prev):\n",
    "        if self.use_read_attention:\n",
    "            return self.read_attention(x, x_hat, h_dec_prev)\n",
    "        else:\n",
    "            return self.read_no_attention(x, x_hat, h_dec_prev)\n",
    "        \n",
    "    def read_no_attention(self, x, x_hat, h_dec_prev):\n",
    "        return tf.concat([x, x_hat], 1)\n",
    "\n",
    "    def read_attention(self, x, x_hat, h_dec_prev):\n",
    "        Fx, Fy, gamma = self.attn_window(h_dec_prev, read_n)\n",
    "\n",
    "        x = filter_img(x, Fx, Fy, gamma, read_n)  # batch x (read_n*read_n)\n",
    "        x_hat = filter_img(x_hat, Fx, Fy, gamma, read_n)\n",
    "        return tf.concat([x, x_hat], 1)  # concat along feature axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-21-7c865655a8a1>(69)attn_window()\n",
      "-> attention_params = tf.matmul(h_dec, self.attention_kernel) + self.attention_bias\n",
      "(Pdb) n\n",
      "> <ipython-input-21-7c865655a8a1>(71)attn_window()\n",
      "-> def filter_batch(batch, Fx, Fy, gamma, N):\n",
      "(Pdb) attention_params\n",
      "<tf.Tensor 'rnn_3/add:0' shape=(3, 5) dtype=float32>\n",
      "(Pdb) attention_params\n",
      "<tf.Tensor 'rnn_3/add:0' shape=(3, 5) dtype=float32>\n",
      "(Pdb) n\n",
      "> <ipython-input-21-7c865655a8a1>(79)attn_window()\n",
      "-> gx_, gy_, log_sigma2, log_delta, log_gamma = tf.split(attention_params, 5, 1)\n",
      "(Pdb) n\n",
      "> <ipython-input-21-7c865655a8a1>(80)attn_window()\n",
      "-> gx = (A + 1) / 2 * (gx_ + 1)\n",
      "(Pdb) gx_\n",
      "<tf.Tensor 'rnn_3/split:0' shape=(3, 1) dtype=float32>\n",
      "(Pdb) gy_\n",
      "<tf.Tensor 'rnn_3/split:1' shape=(3, 1) dtype=float32>\n",
      "(Pdb) log_delta\n",
      "<tf.Tensor 'rnn_3/split:3' shape=(3, 1) dtype=float32>\n",
      "(Pdb) n\n",
      "> <ipython-input-21-7c865655a8a1>(81)attn_window()\n",
      "-> gy = (B + 1) / 2 * (gy_ + 1)\n",
      "(Pdb) n\n",
      "> <ipython-input-21-7c865655a8a1>(82)attn_window()\n",
      "-> sigma2 = tf.exp(log_sigma2)\n",
      "(Pdb) n\n",
      "> <ipython-input-21-7c865655a8a1>(83)attn_window()\n",
      "-> delta = (max(A, B) - 1) / (N - 1) * tf.exp(log_delta)  # batch x N\n",
      "(Pdb) n\n",
      "> <ipython-input-21-7c865655a8a1>(84)attn_window()\n",
      "-> return gaussian_filterbank(gx, gy, sigma2, delta, N) + (tf.exp(log_gamma),)\n",
      "(Pdb) n\n",
      "ValueError: Dimensions must be equal, but are 28 and 3 for 'rnn_3/truediv_2' (op: 'RealDiv') with input shapes: [3,5,28], [3].\n",
      "> <ipython-input-21-7c865655a8a1>(84)attn_window()\n",
      "-> return gaussian_filterbank(gx, gy, sigma2, delta, N) + (tf.exp(log_gamma),)\n"
     ]
    }
   ],
   "source": [
    "cell = DRAWRNNCell(\n",
    "    img_size,\n",
    "    (img_size, enc_size, dec_size),\n",
    "    read_attention=True,\n",
    "    write_attention=True)\n",
    "\n",
    "layer = tf.keras.layers.RNN(cell)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(BATCH_SIZE, A, B))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "# Same input at each time step\n",
    "x = tf.keras.layers.RepeatVector(SEQ_LENGTH)(x)\n",
    "y = layer(x)\n",
    "model = Model(inputs=inputs, outputs=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10, 784])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
