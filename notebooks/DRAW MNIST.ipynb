{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "from tensorflow.keras.layers import RNN, Flatten, RepeatVector\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_ATTN = True\n",
    "WRITE_ATTN = True\n",
    "\n",
    "A, B = 28, 28  # image width,height\n",
    "img_size = B * A  # the canvas size\n",
    "enc_size = 256  # number of hidden units / output size in LSTM\n",
    "dec_size = 256\n",
    "\n",
    "# Glimpse grid dimensions ASSUMED TO BE ODD\n",
    "read_n = 5  # read glimpse grid width/height\n",
    "write_n = 5  # write glimpse grid width/height\n",
    "read_size = 2 * read_n * read_n if READ_ATTN else 2 * img_size\n",
    "write_size = write_n * write_n if WRITE_ATTN else img_size\n",
    "\n",
    "z_size = 10  # QSampler output size\n",
    "SEQ_LENGTH = 10  # MNIST generation sequence length\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_iters = 10000\n",
    "learning_rate = 1e-3  # learning rate for optimizer\n",
    "eps = 1e-8  # epsilon for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/mnist\"\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: (3, 28, 28)\n",
      "Letter: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12d941cf8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = train_ds.__iter__().next()\n",
    "sample = x[0]\n",
    "label = y[0]\n",
    "print(\"Batch Shape: {}\".format(x.shape))\n",
    "print(\"Letter: {}\".format(label))\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filterbank(gx, gy, sigma2, delta, N):\n",
    "    # Grid is 0-indexed, but formula is 1-indexed...\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(1, N+1), tf.float32), [1, -1])\n",
    "    mu_x = gx + (grid_i - N / 2 - 0.5) * delta  # eq 19\n",
    "    mu_y = gy + (grid_i - N / 2 - 0.5) * delta  # eq 20\n",
    "    a_range = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n",
    "    b_range = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n",
    "    mu_x = tf.reshape(mu_x, [-1, N, 1])\n",
    "    mu_y = tf.reshape(mu_y, [-1, N, 1])\n",
    "    sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "    Fx = tf.exp(-tf.square(a_range - mu_x) / (2 * sigma2))\n",
    "    Fy = tf.exp(-tf.square(b_range - mu_y) / (2 * sigma2))  # batch x N x B\n",
    "    \n",
    "    # normalize, sum over A and B dims\n",
    "    Fx = Fx / tf.maximum(tf.reduce_sum(Fx, [1,2], keepdims=True), eps)\n",
    "    Fy = Fy / tf.maximum(tf.reduce_sum(Fy, [1,2], keepdims=True), eps)\n",
    "    return Fx, Fy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRAWRNNCell(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 state_dim,\n",
    "                 read_attention=True,\n",
    "                 write_attention=True,\n",
    "                 read_n=5,\n",
    "                 write_n=5,\n",
    "                 z_size=10,\n",
    "                **kwargs):\n",
    "        \n",
    "        # Encoder/Decoder LSTM Cells track their own kernels\n",
    "        self.lstm_encoder = tf.keras.layers.LSTMCell(enc_size, kernel_initializer=\"zeros\")\n",
    "        self.lstm_decoder = tf.keras.layers.LSTMCell(dec_size, kernel_initializer=\"zeros\")\n",
    "               \n",
    "        self.enc_state = self.lstm_encoder.get_initial_state(\n",
    "            batch_size=BATCH_SIZE, dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        self.dec_state = self.lstm_decoder.get_initial_state(\n",
    "            batch_size=BATCH_SIZE, dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        self.use_read_attention = read_attention\n",
    "        self.use_write_attention = write_attention\n",
    "        \n",
    "        self.enc_size = enc_size\n",
    "        self.dec_size = dec_size\n",
    "        \n",
    "        self.output_size = output_dim\n",
    "        self.state_size = state_dim\n",
    "        \n",
    "        self.read_n = read_n\n",
    "        self.write_n = write_n\n",
    "        self.z_size = z_size\n",
    "        \n",
    "        self.q_sample_noise = tf.random.normal((BATCH_SIZE, z_size), mean=0, stddev=1)\n",
    "        \n",
    "        super(DRAWRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        # Attention Weights/Bias\n",
    "        self.attention_kernel = self.add_weight(\n",
    "            shape=(dec_size, self.read_n), initializer='glorot_uniform', name='W_att')\n",
    "        \n",
    "        self.attention_bias = self.add_weight(\n",
    "            shape=(self.read_n), initializer='zeros', name='b_att')\n",
    "        \n",
    "        # Q sample mu Weights/Bias\n",
    "        self.q_mu_kernel = self.add_weight(\n",
    "            shape=(dec_size, self.z_size),initializer='glorot_uniform',name='W_q_mu')\n",
    "        \n",
    "        self.q_mu_bias = self.add_weight(\n",
    "            shape=(self.z_size), initializer='zeros',name='b_q_mu')\n",
    "        \n",
    "        # Q sample sigma Weights/Bias\n",
    "        self.q_sigma_kernel = self.add_weight(\n",
    "            shape=(dec_size, self.z_size),initializer='glorot_uniform',name='W_q_sigma')\n",
    "        \n",
    "        self.q_sigma_bias = self.add_weight(\n",
    "            shape=(self.z_size), initializer='zeros',name='b_q_sigma')\n",
    "        \n",
    "        # Write Weights/Bias\n",
    "        if self.use_write_attention:\n",
    "            write_size = self.write_n * self.write_n\n",
    "        else:\n",
    "            # No attention, write the whole image\n",
    "            write_size = self.output_size\n",
    "        \n",
    "        self.write_kernel = self.add_weight(\n",
    "            shape=(dec_size, write_size), initializer='glorot_uniform', name='W_write')\n",
    "        \n",
    "        self.write_bias = self.add_weight(\n",
    "            shape=(write_size), initializer='zeros', name='b_write')\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def encode(self, input, state):\n",
    "        return self.lstm_encoder(input, state)\n",
    "    \n",
    "    def decode(self, input, state):\n",
    "        return self.lstm_decoder(input, state)\n",
    "        \n",
    "    def call(self, inputs, states):\n",
    "\n",
    "        c_prev, h_dec_prev, _, _, _ = states\n",
    "        x = inputs\n",
    "               \n",
    "        # Error image (3)\n",
    "        x_hat = x - tf.sigmoid(c_prev)\n",
    "        # Read (4)\n",
    "        glimpse = self.read(x, x_hat, h_dec_prev)\n",
    "        # Encode (5)\n",
    "        h_enc, self.enc_state = self.encode(tf.concat([glimpse, h_dec_prev], 1), self.enc_state)\n",
    "        # Sample (6)\n",
    "        z, mu, log_sigma, sigma = self.sample_q(h_enc)\n",
    "\n",
    "        # Decode (7)\n",
    "        h_dec, self.dec_state = self.decode(z, self.dec_state)\n",
    "        # Write (8)\n",
    "        c_out = c_prev + self.write(h_dec)\n",
    "    \n",
    "        # Return canvas as output & pass along as part of state\n",
    "        return c_out, [c_out, h_dec, mu, log_sigma, sigma]\n",
    "    \n",
    "    def read(self, x, x_hat, h_dec_prev):\n",
    "        if self.use_read_attention:\n",
    "            return self.read_attention(x, x_hat, h_dec_prev)\n",
    "        else:\n",
    "            return self.read_no_attention(x, x_hat, h_dec_prev)\n",
    "        \n",
    "    def read_no_attention(self, x, x_hat, h_dec_prev):\n",
    "        return tf.concat([x, x_hat], 1)\n",
    "\n",
    "    def read_attention(self, x, x_hat, h_dec_prev):\n",
    "        Fx, Fy, gamma = self.attn_window(h_dec_prev, read_n)\n",
    "\n",
    "        x = self._filter_batch(x, Fx, Fy, gamma, read_n)  # batch x (read_n*read_n)\n",
    "        x_hat = self._filter_batch(x_hat, Fx, Fy, gamma, read_n)\n",
    "        return tf.concat([x, x_hat], 1)  # concat along feature axis\n",
    "    \n",
    "    def write(self, h_dec):\n",
    "        if self.use_write_attention:\n",
    "            return self.write_attention(h_dec)\n",
    "        else:\n",
    "            return self.write_no_attention(h_dec)\n",
    "    \n",
    "    def write_no_attention(self, h_dec):\n",
    "        return tf.matmul(h_dec, self.write_kernel) + self.write_bias\n",
    "    \n",
    "    def write_attention(self, h_dec):\n",
    "        ww = tf.matmul(h_dec, self.write_kernel) + self.write_bias\n",
    "        N = self.write_n\n",
    "        ww = tf.reshape(ww, [BATCH_SIZE, N, N])\n",
    "        Fx, Fy, gamma = self.attn_window(h_dec, write_n)\n",
    "        Fyt = tf.transpose(Fy, perm=[0, 2, 1])\n",
    "        wr = tf.matmul(Fyt, tf.matmul(ww, Fx))\n",
    "        wr = tf.reshape(wr, [BATCH_SIZE, B * A])\n",
    "        return wr * tf.reshape(1.0 / gamma, [-1, 1])\n",
    "    \n",
    "    def attn_window(self, h_dec, N):\n",
    "        attention_params = tf.matmul(h_dec, self.attention_kernel) + self.attention_bias\n",
    "\n",
    "        gx_, gy_, log_sigma2, log_delta, log_gamma = tf.split(attention_params, 5, 1)\n",
    "        gx = (A + 1) / 2 * (gx_ + 1)\n",
    "        gy = (B + 1) / 2 * (gy_ + 1)\n",
    "        sigma2 = tf.exp(log_sigma2)\n",
    "        delta = (max(A, B) - 1) / (N - 1) * tf.exp(log_delta)  # batch x N\n",
    "        return gaussian_filterbank(gx, gy, sigma2, delta, N) + (tf.exp(log_gamma),)\n",
    "    \n",
    "    def _filter_batch(self, x, Fx, Fy, gamma, N):\n",
    "        x = tf.reshape(x, [-1, B, A])\n",
    "        Fxt = tf.transpose(Fx, perm=[0, 2, 1])\n",
    "        glimpse = tf.matmul(Fy, tf.matmul(x, Fxt)) \n",
    "        glimpse = tf.reshape(glimpse, [-1, N * N])\n",
    "        return glimpse * gamma    \n",
    "   \n",
    "    def sample_q(self, h_enc):\n",
    "        mu = tf.matmul(h_enc, self.q_mu_kernel) + self.q_mu_bias\n",
    "        logsigma = tf.matmul(h_enc, self.q_sigma_kernel) + self.q_sigma_bias\n",
    "        sigma = tf.exp(logsigma)\n",
    "        return mu + sigma * self.q_sample_noise, mu, logsigma, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(t, o):\n",
    "    return -(t * tf.math.log(o + eps) + (1.0 - t) * tf.math.log(1.0 - o + eps))\n",
    "\n",
    "def draw_loss(y_true, y_pred):\n",
    "    pdb.set_trace()\n",
    "    # reconstruction term appears to have been collapsed down to a single scalar value (rather than one per item in minibatch)\n",
    "    x = y_true\n",
    "    c_out, _, h_dec, mu, log_sigma, sigma = y_pred\n",
    "    \n",
    "    x_recons = tf.nn.sigmoid(c_out)\n",
    "\n",
    "    # after computing binary cross entropy, sum across features then take the mean of those sums across minibatches\n",
    "    Lx = tf.reduce_sum(binary_crossentropy(x, x_recons), 1)  # reconstruction term\n",
    "    Lx = tf.reduce_mean(Lx)\n",
    "\n",
    "    kl_terms = [0] * SEQ_LENGTH\n",
    "    \n",
    "    for t in range(SEQ_LENGTH):\n",
    "        mu2 = tf.square(mu[t])\n",
    "        sigma2 = tf.square(sigma[t])\n",
    "        logsig = log_sigma[t]\n",
    "        \n",
    "        kl_terms[t] = (\n",
    "            0.5 * tf.reduce_sum(mu2 + sigma2 - 2 * logsig, 1) - 0.5\n",
    "        )  # each kl term is (1xminibatch)\n",
    "    KL = tf.add_n(\n",
    "        kl_terms\n",
    "    )  # this is 1xminibatch, corresponding to summing kl_terms from 1:T\n",
    "    Lz = tf.reduce_mean(KL)  # average over minibatches\n",
    "\n",
    "    cost = Lx + Lz\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-7-90dc94fcac70>(7)draw_loss()\n",
      "-> x = y_true\n",
      "(Pdb) y_true\n",
      "<tf.Tensor 'rnn_2_target_1:0' shape=(None, None, None) dtype=float32>\n",
      "(Pdb) y_pred\n",
      "<tf.Tensor 'rnn_2/Identity:0' shape=(3, 10, 784) dtype=float32>\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a4a0382b04c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdraw_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0;31m# Creates the model loss and weighted metrics sub-graphs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       \u001b[0;31m# Functions for train, test and predict will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_weights_loss_and_weighted_metrics\u001b[0;34m(self, sample_weights)\u001b[0m\n\u001b[1;32m   1492\u001b[0m       \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m       \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reduction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             \u001b[0mper_sample_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m             weighted_losses = losses_utils.compute_weighted_loss(\n\u001b[1;32m   1556\u001b[0m                 \u001b[0mper_sample_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0mLoss\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-90dc94fcac70>\u001b[0m in \u001b[0;36mdraw_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# reconstruction term appears to have been collapsed down to a single scalar value (rather than one per item in minibatch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-90dc94fcac70>\u001b[0m in \u001b[0;36mdraw_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# reconstruction term appears to have been collapsed down to a single scalar value (rather than one per item in minibatch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cell = DRAWRNNCell(\n",
    "    img_size,\n",
    "    (img_size, dec_size, SEQ_LENGTH, SEQ_LENGTH, SEQ_LENGTH),\n",
    "    read_attention=True,\n",
    "    write_attention=True)\n",
    "\n",
    "inputs = Input(batch_shape=(BATCH_SIZE, A, B))\n",
    "x = Flatten()(inputs)\n",
    "# Same input at each time step\n",
    "x = RepeatVector(SEQ_LENGTH)(x)\n",
    "rnn_out = RNN(cell, return_sequences=True, return_state=True)(x)\n",
    "canvas, _, _, mu, log_sigma, sigma = rnn_out\n",
    "\n",
    "optimizer = Adam(learning_rate, beta_1=0.5, clipnorm=5.0)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[canvas, mu, log_sigma, sigma])\n",
    "\n",
    "model.compile(loss=draw_loss, optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
