{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/mnist\"\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: (3, 28, 28)\n",
      "Letter: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13419a710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = train_ds.__iter__().next()\n",
    "sample = x[0]\n",
    "label = y[0]\n",
    "print(\"Batch Shape: {}\".format(x.shape))\n",
    "print(\"Letter: {}\".format(label))\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_ATTN = True\n",
    "WRITE_ATTN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = 28, 28  # image width,height\n",
    "img_size = B * A  # the canvas size\n",
    "enc_size = 256  # number of hidden units / output size in LSTM\n",
    "dec_size = 256\n",
    "\n",
    "# Glimpse grid dimensions ASSUMED TO BE ODD\n",
    "read_n = 5  # read glimpse grid width/height\n",
    "write_n = 5  # write glimpse grid width/height\n",
    "read_size = 2 * read_n * read_n if READ_ATTN else 2 * img_size\n",
    "write_size = write_n * write_n if WRITE_ATTN else img_size\n",
    "\n",
    "z_size = 10  # QSampler output size\n",
    "SEQ_LENGTH = 10  # MNIST generation sequence length\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_iters = 10000\n",
    "learning_rate = 1e-3  # learning rate for optimizer\n",
    "eps = 1e-8  # epsilon for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterbank(gx, gy, sigma2, delta, N):\n",
    "    # Grid is 0-indexed, but formula is 1-indexed...\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(1, N+1), tf.float32), [1, -1])\n",
    "    mu_x = gx + (grid_i - N / 2 - 0.5) * delta  # eq 19\n",
    "    mu_y = gy + (grid_i - N / 2 - 0.5) * delta  # eq 20\n",
    "    a_range = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n",
    "    b_range = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n",
    "    mu_x = tf.reshape(mu_x, [-1, N, 1])\n",
    "    mu_y = tf.reshape(mu_y, [-1, N, 1])\n",
    "    sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "    Fx = tf.exp(-tf.square(a_range - mu_x) / (2 * sigma2))\n",
    "    Fy = tf.exp(-tf.square(b_range - mu_y) / (2 * sigma2))  # batch x N x B\n",
    "    # normalize, sum over A and B dims\n",
    "    Fx = Fx / tf.maximum(tf.reduce_sum(Fx, [1,2]), eps)\n",
    "    Fy = Fy / tf.maximum(tf.reduce_sum(Fy, [1,2]), eps)\n",
    "    return Fx, Fy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sample check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch sample check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 25)\n"
     ]
    }
   ],
   "source": [
    "Fx, Fy = filterbank(gx, gy, sigma2, delta, N)\n",
    "Fx = tf.tile(Fx, [BATCH_SIZE, 1, 1])\n",
    "Fy = tf.tile(Fy, [BATCH_SIZE, 1, 1])\n",
    "sample_batch = tf.cast(x, tf.float32)\n",
    "\n",
    "Fxt = tf.transpose(Fx, perm=[0, 2, 1])\n",
    "\n",
    "glimpses = tf.linalg.matmul(Fy, tf.linalg.matmul(sample_batch, Fxt))\n",
    "glimpses = tf.reshape(glimpses, [-1, N * N])\n",
    "# print(Fxt.shape)\n",
    "# print(Fy.shape)\n",
    "# print(sample_batch.shape)\n",
    "# print(Fx.shape)\n",
    "print(glimpses.shape)\n",
    "\n",
    "# for i in range(BATCH_SIZE):\n",
    "#     plt.imshow(x[i])\n",
    "#     plt.figure()\n",
    "#     plt.imshow(glimpses[i])\n",
    "#     plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filterbank(gx, gy, sigma2, delta, N):\n",
    "    # Grid is 0-indexed, but formula is 1-indexed...\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(1, N+1), tf.float32), [1, -1])\n",
    "    mu_x = gx + (grid_i - N / 2 - 0.5) * delta  # eq 19\n",
    "    mu_y = gy + (grid_i - N / 2 - 0.5) * delta  # eq 20\n",
    "    a_range = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n",
    "    b_range = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n",
    "    mu_x = tf.reshape(mu_x, [-1, N, 1])\n",
    "    mu_y = tf.reshape(mu_y, [-1, N, 1])\n",
    "    sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "    Fx = tf.exp(-tf.square(a_range - mu_x) / (2 * sigma2))\n",
    "    Fy = tf.exp(-tf.square(b_range - mu_y) / (2 * sigma2))  # batch x N x B\n",
    "    # normalize, sum over A and B dims\n",
    "    Fx = Fx / tf.maximum(tf.reduce_sum(Fx, [1,2]), eps)\n",
    "    Fy = Fy / tf.maximum(tf.reduce_sum(Fy, [1,2]), eps)\n",
    "    return Fx, Fy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRAWRNNCell(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 state_dim,\n",
    "                 read_attention=True,\n",
    "                 write_attention=True,\n",
    "                **kwargs):\n",
    "        \n",
    "        # Encoder/Decoder LSTM Cells track their own kernels\n",
    "        self.lstm_encoder = tf.keras.layers.LSTMCell(enc_size, kernel_initializer=\"zeros\")\n",
    "        self.lstm_decoder = tf.keras.layers.LSTMCell(dec_size, kernel_initializer=\"zeros\")\n",
    "        \n",
    "        self.use_read_attention = read_attention\n",
    "        self.use_write_attention = write_attention\n",
    "        \n",
    "        self.output_size = output_dim\n",
    "        self.state_size = state_dim\n",
    "        \n",
    "        super(DRAWRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.attention_kernel = self.add_weight(\n",
    "            shape=(self.output_size, self.output_size),\n",
    "            initializer='glorot_uniform',\n",
    "            name='W')\n",
    "        \n",
    "        self.attention_bias = self.add_weight(\n",
    "            shape=(self.output_size, self.output_size),\n",
    "            initializer='zeros',\n",
    "            name='b')\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def encode(self, input, state):\n",
    "        return self.lstm_encoder(input, state)\n",
    "    \n",
    "    def decode(self, input, state):\n",
    "        return self.lstm_decoder(input, state)\n",
    "        \n",
    "    def call(self, inputs, states):\n",
    "        \n",
    "#         import pdb; pdb.set_trace()\n",
    "        \n",
    "        c_prev, enc_prev, dec_prev = states\n",
    "        x = inputs\n",
    "        # Error image (3)\n",
    "        x_hat = x - tf.sigmoid(c_prev)\n",
    "        # Read (4)\n",
    "        r = self.read(x, x_hat, dec_prev)\n",
    "        # Encode (5)\n",
    "        h_enc, enc_state = self.encode(tf.concat([r, dec_prev], 1), enc_prev)\n",
    "        # Sample (6)\n",
    "        z = sampleQ(h_enc)\n",
    "#         z, mus[t], logsigmas[t], sigmas[t] = sampleQ(h_enc)\n",
    "        # Decode (7)\n",
    "        h_dec, dec_state = self.decode(z, dec_prev)\n",
    "        # Write (8)\n",
    "        c_out = c_prev + write(h_dec)\n",
    "    \n",
    "        # Return canvas as output & pass along as part of state\n",
    "        return c_out, [c_out, h_enc, h_dec]\n",
    "    \n",
    "    def attn_window(self, h_dec, N):\n",
    "        attention_params = tf.matmul(self.attention_kernel, h_dec) + self.attention_bias\n",
    "        \n",
    "        def filter_batch(batch, Fx, Fy, gamma, N):\n",
    "            Fx = tf.tile(Fx, [BATCH_SIZE, 1, 1])\n",
    "            Fy = tf.tile(Fy, [BATCH_SIZE, 1, 1])\n",
    "            Fxt = tf.transpose(Fx, perm=[0, 2, 1])\n",
    "            glimpses = tf.linalg.matmul(Fy, tf.linalg.matmul(sample_batch, Fxt))\n",
    "            glimpses = tf.reshape(glimpse, [-1, N * N])\n",
    "            return glimpses * gamma\n",
    "        \n",
    "        gx_, gy_, log_sigma2, log_delta, log_gamma = tf.split(attention_params, 5, 1)\n",
    "        gx = (A + 1) / 2 * (gx_ + 1)\n",
    "        gy = (B + 1) / 2 * (gy_ + 1)\n",
    "        sigma2 = tf.exp(log_sigma2)\n",
    "        delta = (max(A, B) - 1) / (N - 1) * tf.exp(log_delta)  # batch x N\n",
    "        return gaussian_filterbank(gx, gy, sigma2, delta, N) + (tf.exp(log_gamma),)\n",
    "    \n",
    "    def read(self, x, x_hat, h_dec_prev):\n",
    "        if self.use_read_attention:\n",
    "            return self.read_attention(x, x_hat, h_dec_prev)\n",
    "        else:\n",
    "            return self.read_no_attention(x, x_hat, h_dec_prev)\n",
    "        \n",
    "    def read_no_attention(self, x, x_hat, h_dec_prev):\n",
    "        return tf.concat([x, x_hat], 1)\n",
    "\n",
    "    def read_attention(self, x, x_hat, h_dec_prev):\n",
    "        Fx, Fy, gamma = self.attn_window(h_dec_prev, read_n)\n",
    "\n",
    "        x = filter_img(x, Fx, Fy, gamma, read_n)  # batch x (read_n*read_n)\n",
    "        x_hat = filter_img(x_hat, Fx, Fy, gamma, read_n)\n",
    "        return tf.concat([x, x_hat], 1)  # concat along feature axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 784 and 3 for 'rnn_19/MatMul' (op: 'MatMul') with input shapes: [784,784], [3,256].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 784 and 3 for 'rnn_19/MatMul' (op: 'MatMul') with input shapes: [784,784], [3,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-5a8b5a55ede7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRepeatVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    661\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         zero_output_for_mask=self.zero_output_for_mask)\n\u001b[0m\u001b[1;32m    744\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m       \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[0;31m# the value is discarded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3805\u001b[0m     output_time_zero, _ = step_function(\n\u001b[0;32m-> 3806\u001b[0;31m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[1;32m   3807\u001b[0m     output_ta = tuple(\n\u001b[1;32m   3808\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    726\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_tf_rnn_cell\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m           \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-976e0c2482ad>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Read (4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Encode (5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mh_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_prev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-976e0c2482ad>\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, x, x_hat, h_dec_prev)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_read_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_no_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-976e0c2482ad>\u001b[0m in \u001b[0;36mread_attention\u001b[0;34m(self, x, x_hat, h_dec_prev)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mFx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_dec_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_n\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# batch x (read_n*read_n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-976e0c2482ad>\u001b[0m in \u001b[0;36mattn_window\u001b[0;34m(self, h_dec, N)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mattn_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mattention_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfilter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2647\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5923\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   5924\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5925\u001b[0;31m                   name=name)\n\u001b[0m\u001b[1;32m   5926\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5927\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    463\u001b[0m     return super(FuncGraph, self).create_op(\n\u001b[1;32m    464\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         compute_device=compute_device)\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3294\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3295\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3296\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3297\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1712\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1713\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1714\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 784 and 3 for 'rnn_19/MatMul' (op: 'MatMul') with input shapes: [784,784], [3,256]."
     ]
    }
   ],
   "source": [
    "cell = DRAWRNNCell(\n",
    "    img_size,\n",
    "    (img_size, enc_size, dec_size),\n",
    "    read_attention=True,\n",
    "    write_attention=True)\n",
    "\n",
    "layer = tf.keras.layers.RNN(cell)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(BATCH_SIZE, A, B))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.RepeatVector(SEQ_LENGTH)(x)\n",
    "y = layer(x)\n",
    "model = Model(inputs=inputs, outputs=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10, 784])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
