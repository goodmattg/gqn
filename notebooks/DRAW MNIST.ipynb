{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_ATTN = True\n",
    "WRITE_ATTN = True\n",
    "\n",
    "A, B = 28, 28  # image width,height\n",
    "img_size = B * A  # the canvas size\n",
    "enc_size = 256  # number of hidden units / output size in LSTM\n",
    "dec_size = 256\n",
    "\n",
    "# Glimpse grid dimensions ASSUMED TO BE ODD\n",
    "read_n = 5  # read glimpse grid width/height\n",
    "write_n = 5  # write glimpse grid width/height\n",
    "read_size = 2 * read_n * read_n if READ_ATTN else 2 * img_size\n",
    "write_size = write_n * write_n if WRITE_ATTN else img_size\n",
    "\n",
    "z_size = 10  # QSampler output size\n",
    "SEQ_LENGTH = 10  # MNIST generation sequence length\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_iters = 10000\n",
    "learning_rate = 1e-3  # learning rate for optimizer\n",
    "eps = 1e-8  # epsilon for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/mnist\"\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: (3, 28, 28)\n",
      "Letter: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x129155e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = train_ds.__iter__().next()\n",
    "sample = x[0]\n",
    "label = y[0]\n",
    "print(\"Batch Shape: {}\".format(x.shape))\n",
    "print(\"Letter: {}\".format(label))\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filterbank(gx, gy, sigma2, delta, N):\n",
    "    # Grid is 0-indexed, but formula is 1-indexed...\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(1, N+1), tf.float32), [1, -1])\n",
    "    mu_x = gx + (grid_i - N / 2 - 0.5) * delta  # eq 19\n",
    "    mu_y = gy + (grid_i - N / 2 - 0.5) * delta  # eq 20\n",
    "    a_range = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n",
    "    b_range = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n",
    "    mu_x = tf.reshape(mu_x, [-1, N, 1])\n",
    "    mu_y = tf.reshape(mu_y, [-1, N, 1])\n",
    "    sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "    Fx = tf.exp(-tf.square(a_range - mu_x) / (2 * sigma2))\n",
    "    Fy = tf.exp(-tf.square(b_range - mu_y) / (2 * sigma2))  # batch x N x B\n",
    "    \n",
    "    # normalize, sum over A and B dims\n",
    "    Fx = Fx / tf.maximum(tf.reduce_sum(Fx, [1,2], keepdims=True), eps)\n",
    "    Fy = Fy / tf.maximum(tf.reduce_sum(Fy, [1,2], keepdims=True), eps)\n",
    "    return Fx, Fy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRAWRNNCell(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 state_dim,\n",
    "                 read_attention=True,\n",
    "                 write_attention=True,\n",
    "                 read_n=5,\n",
    "                 write_n=5,\n",
    "                 z_size=10,\n",
    "                **kwargs):\n",
    "        \n",
    "        # Encoder/Decoder LSTM Cells track their own kernels\n",
    "        self.lstm_encoder = tf.keras.layers.LSTMCell(enc_size, kernel_initializer=\"zeros\")\n",
    "        self.lstm_decoder = tf.keras.layers.LSTMCell(dec_size, kernel_initializer=\"zeros\")\n",
    "               \n",
    "        self.enc_state = self.lstm_encoder.get_initial_state(\n",
    "            batch_size=BATCH_SIZE, dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        self.dec_state = self.lstm_decoder.get_initial_state(\n",
    "            batch_size=BATCH_SIZE, dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        self.use_read_attention = read_attention\n",
    "        self.use_write_attention = write_attention\n",
    "        \n",
    "        self.enc_size = enc_size\n",
    "        self.dec_size = dec_size\n",
    "        \n",
    "        self.output_size = output_dim\n",
    "        self.state_size = state_dim\n",
    "        \n",
    "        self.read_n = read_n\n",
    "        self.write_n = write_n\n",
    "        self.z_size = z_size\n",
    "        \n",
    "        self.q_sample_noise = tf.random.normal((BATCH_SIZE, z_size), mean=0, stddev=1)\n",
    "        \n",
    "        super(DRAWRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.attention_kernel = self.add_weight(\n",
    "            shape=(dec_size, self.read_n),\n",
    "            initializer='glorot_uniform',\n",
    "            name='W_att')\n",
    "        \n",
    "        self.attention_bias = self.add_weight(\n",
    "            shape=(self.read_n),\n",
    "            initializer='zeros',\n",
    "            name='b_att')\n",
    "        \n",
    "        self.q_kernel = self.add_weight(\n",
    "            shape=(dec_size, self.z_size),\n",
    "            initializer='glorot_uniform',\n",
    "            name='W_sample_q')\n",
    "        \n",
    "        self.q_bias = self.add_weight(\n",
    "            shape=(self.z_size),\n",
    "            initializer='zeros',\n",
    "            name='b_sample_q')\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def encode(self, input, state):\n",
    "        return self.lstm_encoder(input, state)\n",
    "    \n",
    "    def decode(self, input, state):\n",
    "        return self.lstm_decoder(input, state)\n",
    "        \n",
    "    def call(self, inputs, states):\n",
    "\n",
    "        c_prev, h_dec_prev= states\n",
    "        x = inputs\n",
    "               \n",
    "        # Error image (3)\n",
    "        x_hat = x - tf.sigmoid(c_prev)\n",
    "        # Read (4)\n",
    "        glimpse = self.read(x, x_hat, h_dec_prev)\n",
    "        \n",
    "        # Encode (5)\n",
    "        h_enc, self.enc_state = self.encode(tf.concat([glimpse, h_dec_prev], 1), self.enc_state)\n",
    "\n",
    "        pdb.set_trace()\n",
    "        \n",
    "        # Sample (6)\n",
    "        z = self.sample_q(h_enc)\n",
    "#         z, mus[t], logsigmas[t], sigmas[t] = sampleQ(h_enc)\n",
    "        # Decode (7)\n",
    "        h_dec, self.dec_state = self.decode(z, self.dec_state)\n",
    "        # Write (8)\n",
    "        c_out = c_prev + write(h_dec)\n",
    "    \n",
    "        # Return canvas as output & pass along as part of state\n",
    "        return c_out, [c_out, h_dec]\n",
    "    \n",
    "    def read(self, x, x_hat, h_dec_prev):\n",
    "        if self.use_read_attention:\n",
    "            return self.read_attention(x, x_hat, h_dec_prev)\n",
    "        else:\n",
    "            return self.read_no_attention(x, x_hat, h_dec_prev)\n",
    "        \n",
    "    def read_no_attention(self, x, x_hat, h_dec_prev):\n",
    "        return tf.concat([x, x_hat], 1)\n",
    "\n",
    "    def read_attention(self, x, x_hat, h_dec_prev):\n",
    "        Fx, Fy, gamma = self.attn_window(h_dec_prev, read_n)\n",
    "\n",
    "        x = self._filter_batch(x, Fx, Fy, gamma, read_n)  # batch x (read_n*read_n)\n",
    "        x_hat = self._filter_batch(x_hat, Fx, Fy, gamma, read_n)\n",
    "        return tf.concat([x, x_hat], 1)  # concat along feature axis\n",
    "    \n",
    "    def attn_window(self, h_dec, N):\n",
    "        attention_params = tf.matmul(h_dec, self.attention_kernel) + self.attention_bias\n",
    "\n",
    "        gx_, gy_, log_sigma2, log_delta, log_gamma = tf.split(attention_params, 5, 1)\n",
    "        gx = (A + 1) / 2 * (gx_ + 1)\n",
    "        gy = (B + 1) / 2 * (gy_ + 1)\n",
    "        sigma2 = tf.exp(log_sigma2)\n",
    "        delta = (max(A, B) - 1) / (N - 1) * tf.exp(log_delta)  # batch x N\n",
    "        return gaussian_filterbank(gx, gy, sigma2, delta, N) + (tf.exp(log_gamma),)\n",
    "    \n",
    "    def _filter_batch(self, x, Fx, Fy, gamma, N):\n",
    "        x = tf.reshape(x, [-1, B, A])\n",
    "        Fxt = tf.transpose(Fx, perm=[0, 2, 1])\n",
    "        glimpse = tf.linalg.matmul(Fy, tf.linalg.matmul(x, Fxt))\n",
    "        glimpse = tf.reshape(glimpse, [-1, N * N])\n",
    "        return glimpse * gamma    \n",
    "   \n",
    "    def sample_q(self, h_enc):\n",
    "        mu = tf.matmul(h_enc, self.q_kernel) + self.q_bias\n",
    "        logsigma = tf.matmul(h_enc, self.q_kernel) + self.q_bias\n",
    "        sigma = tf.exp(logsigma)\n",
    "        return mu + sigma * self.q_sample_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-b31b7f12f8a2>(88)call()\n",
      "-> z = self.sample_q(h_enc)\n",
      "(Pdb) n\n",
      "> <ipython-input-10-b31b7f12f8a2>(91)call()\n",
      "-> h_dec, self.dec_state = self.decode(z, self.dec_state)\n",
      "(Pdb) n\n",
      "> <ipython-input-10-b31b7f12f8a2>(93)call()\n",
      "-> c_out = c_prev + write(h_dec)\n",
      "(Pdb) n\n",
      "NameError: name 'write' is not defined\n",
      "> <ipython-input-10-b31b7f12f8a2>(93)call()\n",
      "-> c_out = c_prev + write(h_dec)\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-10bfdf726138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Same input at each time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRepeatVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    661\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         zero_output_for_mask=self.zero_output_for_mask)\n\u001b[0m\u001b[1;32m    744\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m       \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[0;31m# the value is discarded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3805\u001b[0m     output_time_zero, _ = step_function(\n\u001b[0;32m-> 3806\u001b[0;31m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[1;32m   3807\u001b[0m     output_ta = tuple(\n\u001b[1;32m   3808\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    726\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_tf_rnn_cell\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m           \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b31b7f12f8a2>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mh_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Write (8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_prev\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Return canvas as output & pass along as part of state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c_call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_exception\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     and arg[0] is StopIteration and arg[2] is None):\n\u001b[1;32m    173\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Stop at the StopIteration or GeneratorExit exception when the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# has set stopframe in a generator by issuing a return command, or a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cell = DRAWRNNCell(\n",
    "    img_size,\n",
    "    (img_size, dec_size),\n",
    "    read_attention=True,\n",
    "    write_attention=True)\n",
    "\n",
    "layer = tf.keras.layers.RNN(cell)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(BATCH_SIZE, A, B))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "# Same input at each time step\n",
    "x = tf.keras.layers.RepeatVector(SEQ_LENGTH)(x)\n",
    "y = layer(x)\n",
    "model = Model(inputs=inputs, outputs=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = self.lstm_encoder.get_initial_state(batch_size=BATCH_SIZE, dtype=tf.float3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
