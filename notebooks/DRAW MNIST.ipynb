{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/mnist\"\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute '__iterator__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-656f63598cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iterator__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute '__iterator__'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e736320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Letter: {}\".format(y_train[5]))\n",
    "plt.imshow(x_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_ATTN = True\n",
    "WRITE_ATTN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = 28, 28  # image width,height\n",
    "img_size = B * A  # the canvas size\n",
    "enc_size = 256  # number of hidden units / output size in LSTM\n",
    "dec_size = 256\n",
    "read_n = 5  # read glimpse grid width/height\n",
    "write_n = 5  # write glimpse grid width/height\n",
    "read_size = 2 * read_n * read_n if READ_ATTN else 2 * img_size\n",
    "write_size = write_n * write_n if WRITE_ATTN else img_size\n",
    "z_size = 10  # QSampler output size\n",
    "T = 10  # MNIST generation sequence length\n",
    "batch_size = 100  # training minibatch size\n",
    "train_iters = 10000\n",
    "learning_rate = 1e-3  # learning rate for optimizer\n",
    "eps = 1e-8  # epsilon for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples.tutorials'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-814cc27fae97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples.tutorials'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\"\n",
    "Simple implementation of http://arxiv.org/pdf/1502.04623v2.pdf in TensorFlow\n",
    "\n",
    "Example Usage: \n",
    "\tpython draw.py --data_dir=/tmp/draw --read_attn=True --write_attn=True\n",
    "\n",
    "Author: Eric Jang\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials import mnist\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "tf.flags.DEFINE_string(\"data_dir\", \"\", \"\")\n",
    "tf.flags.DEFINE_boolean(\"read_attn\", True, \"enable attention for reader\")\n",
    "tf.flags.DEFINE_boolean(\"write_attn\", True, \"enable attention for writer\")\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "## MODEL PARAMETERS ##\n",
    "\n",
    "A, B = 28, 28  # image width,height\n",
    "img_size = B * A  # the canvas size\n",
    "enc_size = 256  # number of hidden units / output size in LSTM\n",
    "dec_size = 256\n",
    "read_n = 5  # read glimpse grid width/height\n",
    "write_n = 5  # write glimpse grid width/height\n",
    "read_size = 2 * read_n * read_n if FLAGS.read_attn else 2 * img_size\n",
    "write_size = write_n * write_n if FLAGS.write_attn else img_size\n",
    "z_size = 10  # QSampler output size\n",
    "T = 10  # MNIST generation sequence length\n",
    "batch_size = 100  # training minibatch size\n",
    "train_iters = 10000\n",
    "learning_rate = 1e-3  # learning rate for optimizer\n",
    "eps = 1e-8  # epsilon for numerical stability\n",
    "\n",
    "## BUILD MODEL ##\n",
    "\n",
    "DO_SHARE = None  # workaround for variable_scope(reuse=True)\n",
    "\n",
    "x = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, img_size)\n",
    ")  # input (batch_size * img_size)\n",
    "e = tf.random_normal((batch_size, z_size), mean=0, stddev=1)  # Qsampler noise\n",
    "lstm_enc = tf.contrib.rnn.LSTMCell(enc_size, state_is_tuple=True)  # encoder Op\n",
    "lstm_dec = tf.contrib.rnn.LSTMCell(dec_size, state_is_tuple=True)  # decoder Op\n",
    "\n",
    "\n",
    "def linear(x, output_dim):\n",
    "    \"\"\"\n",
    "    affine transformation Wx+b\n",
    "    assumes x.shape = (batch_size, num_features)\n",
    "    \"\"\"\n",
    "    w = tf.get_variable(\"w\", [x.get_shape()[1], output_dim])\n",
    "    b = tf.get_variable(\"b\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(x, w) + b\n",
    "\n",
    "\n",
    "def filterbank(gx, gy, sigma2, delta, N):\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(N), tf.float32), [1, -1])\n",
    "    mu_x = gx + (grid_i - N / 2 - 0.5) * delta  # eq 19\n",
    "    mu_y = gy + (grid_i - N / 2 - 0.5) * delta  # eq 20\n",
    "    a = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n",
    "    b = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n",
    "    mu_x = tf.reshape(mu_x, [-1, N, 1])\n",
    "    mu_y = tf.reshape(mu_y, [-1, N, 1])\n",
    "    sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "    Fx = tf.exp(-tf.square(a - mu_x) / (2 * sigma2))\n",
    "    Fy = tf.exp(-tf.square(b - mu_y) / (2 * sigma2))  # batch x N x B\n",
    "    # normalize, sum over A and B dims\n",
    "    Fx = Fx / tf.maximum(tf.reduce_sum(Fx, 2, keep_dims=True), eps)\n",
    "    Fy = Fy / tf.maximum(tf.reduce_sum(Fy, 2, keep_dims=True), eps)\n",
    "    return Fx, Fy\n",
    "\n",
    "\n",
    "def attn_window(scope, h_dec, N):\n",
    "    with tf.variable_scope(scope, reuse=DO_SHARE):\n",
    "        params = linear(h_dec, 5)\n",
    "    # gx_,gy_,log_sigma2,log_delta,log_gamma=tf.split(1,5,params)\n",
    "    gx_, gy_, log_sigma2, log_delta, log_gamma = tf.split(params, 5, 1)\n",
    "    gx = (A + 1) / 2 * (gx_ + 1)\n",
    "    gy = (B + 1) / 2 * (gy_ + 1)\n",
    "    sigma2 = tf.exp(log_sigma2)\n",
    "    delta = (max(A, B) - 1) / (N - 1) * tf.exp(log_delta)  # batch x N\n",
    "    return filterbank(gx, gy, sigma2, delta, N) + (tf.exp(log_gamma),)\n",
    "\n",
    "\n",
    "## READ ##\n",
    "def read_no_attn(x, x_hat, h_dec_prev):\n",
    "    return tf.concat([x, x_hat], 1)\n",
    "\n",
    "\n",
    "def read_attn(x, x_hat, h_dec_prev):\n",
    "    Fx, Fy, gamma = attn_window(\"read\", h_dec_prev, read_n)\n",
    "\n",
    "    def filter_img(img, Fx, Fy, gamma, N):\n",
    "        Fxt = tf.transpose(Fx, perm=[0, 2, 1])\n",
    "        img = tf.reshape(img, [-1, B, A])\n",
    "        glimpse = tf.matmul(Fy, tf.matmul(img, Fxt))\n",
    "        glimpse = tf.reshape(glimpse, [-1, N * N])\n",
    "        return glimpse * tf.reshape(gamma, [-1, 1])\n",
    "\n",
    "    x = filter_img(x, Fx, Fy, gamma, read_n)  # batch x (read_n*read_n)\n",
    "    x_hat = filter_img(x_hat, Fx, Fy, gamma, read_n)\n",
    "    return tf.concat([x, x_hat], 1)  # concat along feature axis\n",
    "\n",
    "\n",
    "read = read_attn if FLAGS.read_attn else read_no_attn\n",
    "\n",
    "## ENCODE ##\n",
    "def encode(state, input):\n",
    "    \"\"\"\n",
    "    run LSTM\n",
    "    state = previous encoder state\n",
    "    input = cat(read,h_dec_prev)\n",
    "    returns: (output, new_state)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"encoder\", reuse=DO_SHARE):\n",
    "        return lstm_enc(input, state)\n",
    "\n",
    "\n",
    "## Q-SAMPLER (VARIATIONAL AUTOENCODER) ##\n",
    "\n",
    "\n",
    "def sampleQ(h_enc):\n",
    "    \"\"\"\n",
    "    Samples Zt ~ normrnd(mu,sigma) via reparameterization trick for normal dist\n",
    "    mu is (batch,z_size)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"mu\", reuse=DO_SHARE):\n",
    "        mu = linear(h_enc, z_size)\n",
    "    with tf.variable_scope(\"sigma\", reuse=DO_SHARE):\n",
    "        logsigma = linear(h_enc, z_size)\n",
    "        sigma = tf.exp(logsigma)\n",
    "    return (mu + sigma * e, mu, logsigma, sigma)\n",
    "\n",
    "\n",
    "## DECODER ##\n",
    "def decode(state, input):\n",
    "    with tf.variable_scope(\"decoder\", reuse=DO_SHARE):\n",
    "        return lstm_dec(input, state)\n",
    "\n",
    "\n",
    "## WRITER ##\n",
    "def write_no_attn(h_dec):\n",
    "    with tf.variable_scope(\"write\", reuse=DO_SHARE):\n",
    "        return linear(h_dec, img_size)\n",
    "\n",
    "\n",
    "def write_attn(h_dec):\n",
    "    with tf.variable_scope(\"writeW\", reuse=DO_SHARE):\n",
    "        w = linear(h_dec, write_size)  # batch x (write_n*write_n)\n",
    "    N = write_n\n",
    "    w = tf.reshape(w, [batch_size, N, N])\n",
    "    Fx, Fy, gamma = attn_window(\"write\", h_dec, write_n)\n",
    "    Fyt = tf.transpose(Fy, perm=[0, 2, 1])\n",
    "    wr = tf.matmul(Fyt, tf.matmul(w, Fx))\n",
    "    wr = tf.reshape(wr, [batch_size, B * A])\n",
    "    # gamma=tf.tile(gamma,[1,B*A])\n",
    "    return wr * tf.reshape(1.0 / gamma, [-1, 1])\n",
    "\n",
    "\n",
    "write = write_attn if FLAGS.write_attn else write_no_attn\n",
    "\n",
    "## STATE VARIABLES ##\n",
    "\n",
    "cs = [0] * T  # sequence of canvases\n",
    "mus, logsigmas, sigmas = (\n",
    "    [0] * T,\n",
    "    [0] * T,\n",
    "    [0] * T,\n",
    ")  # gaussian params generated by SampleQ. We will need these for computing loss.\n",
    "# initial states\n",
    "h_dec_prev = tf.zeros((batch_size, dec_size))\n",
    "enc_state = lstm_enc.zero_state(batch_size, tf.float32)\n",
    "dec_state = lstm_dec.zero_state(batch_size, tf.float32)\n",
    "\n",
    "## DRAW MODEL ##\n",
    "\n",
    "# construct the unrolled computational graph\n",
    "for t in range(T):\n",
    "    c_prev = tf.zeros((batch_size, img_size)) if t == 0 else cs[t - 1]\n",
    "    x_hat = x - tf.sigmoid(c_prev)  # error image\n",
    "    r = read(x, x_hat, h_dec_prev)\n",
    "    h_enc, enc_state = encode(enc_state, tf.concat([r, h_dec_prev], 1))\n",
    "    z, mus[t], logsigmas[t], sigmas[t] = sampleQ(h_enc)\n",
    "    h_dec, dec_state = decode(dec_state, z)\n",
    "    cs[t] = c_prev + write(h_dec)  # store results\n",
    "    h_dec_prev = h_dec\n",
    "    DO_SHARE = True  # from now on, share variables\n",
    "\n",
    "## LOSS FUNCTION ##\n",
    "\n",
    "\n",
    "def binary_crossentropy(t, o):\n",
    "    return -(t * tf.log(o + eps) + (1.0 - t) * tf.log(1.0 - o + eps))\n",
    "\n",
    "\n",
    "# reconstruction term appears to have been collapsed down to a single scalar value (rather than one per item in minibatch)\n",
    "x_recons = tf.nn.sigmoid(cs[-1])\n",
    "\n",
    "# after computing binary cross entropy, sum across features then take the mean of those sums across minibatches\n",
    "Lx = tf.reduce_sum(binary_crossentropy(x, x_recons), 1)  # reconstruction term\n",
    "Lx = tf.reduce_mean(Lx)\n",
    "\n",
    "kl_terms = [0] * T\n",
    "for t in range(T):\n",
    "    mu2 = tf.square(mus[t])\n",
    "    sigma2 = tf.square(sigmas[t])\n",
    "    logsigma = logsigmas[t]\n",
    "    kl_terms[t] = (\n",
    "        0.5 * tf.reduce_sum(mu2 + sigma2 - 2 * logsigma, 1) - 0.5\n",
    "    )  # each kl term is (1xminibatch)\n",
    "KL = tf.add_n(\n",
    "    kl_terms\n",
    ")  # this is 1xminibatch, corresponding to summing kl_terms from 1:T\n",
    "Lz = tf.reduce_mean(KL)  # average over minibatches\n",
    "\n",
    "cost = Lx + Lz\n",
    "\n",
    "## OPTIMIZER ##\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
    "grads = optimizer.compute_gradients(cost)\n",
    "for i, (g, v) in enumerate(grads):\n",
    "    if g is not None:\n",
    "        grads[i] = (tf.clip_by_norm(g, 5), v)  # clip gradients\n",
    "train_op = optimizer.apply_gradients(grads)\n",
    "\n",
    "## RUN TRAINING ##\n",
    "\n",
    "data_directory = os.path.join(FLAGS.data_dir, \"mnist\")\n",
    "if not os.path.exists(data_directory):\n",
    "    os.makedirs(data_directory)\n",
    "train_data = mnist.input_data.read_data_sets(\n",
    "    data_directory, one_hot=True\n",
    ").train  # binarized (0-1) mnist data\n",
    "\n",
    "fetches = []\n",
    "fetches.extend([Lx, Lz, train_op])\n",
    "Lxs = [0] * train_iters\n",
    "Lzs = [0] * train_iters\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "saver = tf.train.Saver()  # saves variables learned during training\n",
    "tf.global_variables_initializer().run()\n",
    "saver.restore(\n",
    "    sess, \"/tmp/draw/drawmodel_noattn.ckpt\"\n",
    ")  # to restore from model, uncomment this line\n",
    "\n",
    "for i in range(train_iters):\n",
    "    xtrain, _ = train_data.next_batch(batch_size)  # xtrain is (batch_size x img_size)\n",
    "    feed_dict = {x: xtrain}\n",
    "    results = sess.run(fetches, feed_dict)\n",
    "    Lxs[i], Lzs[i], _ = results\n",
    "    if i % 100 == 0:\n",
    "        print(\"iter=%d : Lx: %f Lz: %f\" % (i, Lxs[i], Lzs[i]))\n",
    "\n",
    "## TRAINING FINISHED ##\n",
    "\n",
    "canvases = sess.run(cs, feed_dict)  # generate some examples\n",
    "canvases = np.array(canvases)  # T x batch x img_size\n",
    "\n",
    "out_file = os.path.join(FLAGS.data_dir, \"draw_data.npy\")\n",
    "np.save(out_file, [canvases, Lxs, Lzs])\n",
    "print(\"Outputs saved in file: %s\" % out_file)\n",
    "\n",
    "ckpt_file = os.path.join(FLAGS.data_dir, \"drawmodel.ckpt\")\n",
    "print(\"Model saved in file: %s\" % saver.save(sess, ckpt_file))\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
